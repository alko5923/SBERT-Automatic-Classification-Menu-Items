{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exjobb-custom-metric-prep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will implement a custom metric for measuring the quality of the classification based on embeddings.  "
      ],
      "metadata": {
        "id": "FOobbcvndqW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkM4BwASO213"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Change this line if you want to display more than 10 rows when printing\n",
        "pd.set_option('display.max_rows', 70)\n",
        "\n",
        "df_original = pd.read_csv('/content/original-1-classified.csv')\n",
        "df_processed = pd.read_csv('/content/processed-1-classified.csv')\n",
        "\n",
        "# Inspect the data\n",
        "print(\"Df_orig classes value counts = \\n\", df_original['Class1'].value_counts(), \"\\n\")\n",
        "print(\"Df_proc classes value counts = \\n\", df_processed['Class1'].value_counts(), \"\\n\")\n",
        "\n",
        "# Remove duplicate rows based on all columns\n",
        "df_orig = df_original.drop_duplicates(ignore_index=True)\n",
        "df_proc = df_processed.drop_duplicates(ignore_index=True)\n",
        "\n",
        "# Inspect the data again\n",
        "print(\"Df_original with duplicates removed = \\n\", df_orig['Class1'].value_counts(), \"\\n\")\n",
        "print(\"Df_processed with duplicates removed = \\n\", df_proc['Class1'].value_counts(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Fz0nYzsFHu",
        "outputId": "c55f8558-975d-4f09-87aa-71e3f6ef0a6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Df_orig classes value counts = \n",
            " VariedFood       120\n",
            "Beer             110\n",
            "Spirits          101\n",
            "Wine              72\n",
            "SoftDrinks        50\n",
            "CoffeeTeaMilk     32\n",
            "Burger            21\n",
            "Kids              14\n",
            "Cider             14\n",
            "Wings             12\n",
            "Dessert           11\n",
            "Other              7\n",
            "Champagne          5\n",
            "Salad              5\n",
            "Name: Class1, dtype: int64 \n",
            "\n",
            "Df_proc classes value counts = \n",
            " VariedFood       119\n",
            "Beer              95\n",
            "Spirits           94\n",
            "Wine              73\n",
            "SoftDrinks        43\n",
            "CoffeeTeaMilk     32\n",
            "Burger            21\n",
            "Kids              14\n",
            "Cider             14\n",
            "Wings             12\n",
            "Dessert           11\n",
            "Other              7\n",
            "Champagne          5\n",
            "Salad              5\n",
            "Name: Class1, dtype: int64 \n",
            "\n",
            "Df_original with duplicates removed = \n",
            " VariedFood       120\n",
            "Beer             105\n",
            "Spirits          101\n",
            "Wine              71\n",
            "SoftDrinks        50\n",
            "CoffeeTeaMilk     32\n",
            "Burger            21\n",
            "Kids              14\n",
            "Cider             14\n",
            "Wings             12\n",
            "Dessert           11\n",
            "Other              7\n",
            "Champagne          5\n",
            "Salad              5\n",
            "Name: Class1, dtype: int64 \n",
            "\n",
            "Df_processed with duplicates removed = \n",
            " VariedFood       117\n",
            "Spirits           79\n",
            "Wine              66\n",
            "Beer              60\n",
            "SoftDrinks        32\n",
            "CoffeeTeaMilk     29\n",
            "Burger            21\n",
            "Kids              14\n",
            "Cider             14\n",
            "Dessert           11\n",
            "Other              7\n",
            "Wings              5\n",
            "Salad              5\n",
            "Champagne          4\n",
            "Name: Class1, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform one-hot encoding of the categorical variables and concatenate with the original dataframe. "
      ],
      "metadata": {
        "id": "uZmMLlsufGqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding of the Class1 columns\n",
        "one_hot_columns_orig = pd.get_dummies(df_orig['Class1'])\n",
        "one_hot_columns_proc = pd.get_dummies(df_proc['Class1'])\n",
        "# Concatenate\n",
        "df_orig_onehot = pd.concat([df_orig, one_hot_columns_orig], axis=1)\n",
        "print(df_orig_onehot)\n",
        "\n",
        "df_proc_onehot = pd.concat([df_proc, one_hot_columns_proc], axis=1)\n",
        "print(df_proc_onehot)"
      ],
      "metadata": {
        "id": "vZMY7_xksZJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the embeddings of the items for all 3 models and save them with the one-hot encoded columns. "
      ],
      "metadata": {
        "id": "CxRBPZ1yf6H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\"\"\"\n",
        "Create embeddings for the items.\n",
        "Models: \n",
        "'distiluse-base-multilingual-cased-v2',  \n",
        "'paraphrase-multilingual-MiniLM-L12-v2' and\n",
        "'paraphrase-multilingual-mpnet-base-v2'.\n",
        "\"\"\"\n",
        "# Define the models\n",
        "model_distiluse = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
        "model_para_mini = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "model_para_base = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        "\n",
        "# Read items from the file into a list\n",
        "items_original = df_orig_onehot['ArticleName'].tolist()\n",
        "items_processed = df_proc_onehot['ArticleName'].tolist()\n",
        "\n",
        "# Calculate embeddings\n",
        "orig_embeddings_distiluse = model_distiluse.encode(items_original)\n",
        "orig_embeddings_para_mini = model_para_mini.encode(items_original)\n",
        "orig_embeddings_para_base = model_para_base.encode(items_original)\n",
        "\n",
        "proc_embeddings_distiluse = model_distiluse.encode(items_processed)\n",
        "proc_embeddings_para_mini = model_para_mini.encode(items_processed)\n",
        "proc_embeddings_para_base = model_para_base.encode(items_processed)"
      ],
      "metadata": {
        "id": "wcNsSPJigLRf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the original dataset \n",
        "\n",
        "# Save the embeddings into the dataframe\n",
        "# Create names of features for distiluse\n",
        "features_names_distiluse = []\n",
        "for i in range(len(orig_embeddings_distiluse[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_distiluse.append(name)\n",
        "\n",
        "# Create names of features for para-mini\n",
        "features_names_para_mini = []\n",
        "for i in range(len(orig_embeddings_para_mini[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_mini.append(name)\n",
        "\n",
        "# Create names of features for para-base\n",
        "features_names_para_base = []\n",
        "for i in range(len(orig_embeddings_para_base[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_base.append(name)\n",
        "\n",
        "\n",
        "# Save the distiluse dataframe\n",
        "df_emb_distiluse_orig = pd.DataFrame(orig_embeddings_distiluse, columns=features_names_distiluse)\n",
        "# Concatenate the dataframes\n",
        "df_orig_distiluse_class_onehot = pd.concat([df_orig_onehot, df_emb_distiluse_orig], axis=1)\n",
        "\n",
        "# Save the para_mini dataframe\n",
        "df_emb_para_mini_orig = pd.DataFrame(orig_embeddings_para_mini, columns=features_names_para_mini)\n",
        "# Concatenate the dataframes\n",
        "df_orig_para_mini_class_onehot = pd.concat([df_orig_onehot, df_emb_para_mini_orig], axis=1)\n",
        "\n",
        "# Save the para_base dataframe\n",
        "df_emb_para_base_orig = pd.DataFrame(orig_embeddings_para_base, columns=features_names_para_base)\n",
        "# Concatenate the dataframes\n",
        "df_orig_para_base_class_onehot = pd.concat([df_orig_onehot, df_emb_para_base_orig], axis=1)"
      ],
      "metadata": {
        "id": "6b6hdHlNqK15"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the processed dataset \n",
        "\n",
        "# Save the embeddings into the dataframe\n",
        "# Create names of features for distiluse\n",
        "features_names_distiluse = []\n",
        "for i in range(len(proc_embeddings_distiluse[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_distiluse.append(name)\n",
        "\n",
        "# Create names of features for para-mini\n",
        "features_names_para_mini = []\n",
        "for i in range(len(proc_embeddings_para_mini[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_mini.append(name)\n",
        "\n",
        "# Create names of features for para-base\n",
        "features_names_para_base = []\n",
        "for i in range(len(proc_embeddings_para_base[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_base.append(name)\n",
        "\n",
        "\n",
        "# Save the distiluse dataframe\n",
        "df_emb_distiluse_proc = pd.DataFrame(proc_embeddings_distiluse, columns=features_names_distiluse)\n",
        "# Concatenate the dataframes\n",
        "df_proc_distiluse_class_onehot = pd.concat([df_proc_onehot, df_emb_distiluse_proc], axis=1)\n",
        "\n",
        "# Save the para_mini dataframe\n",
        "df_emb_para_mini_proc = pd.DataFrame(proc_embeddings_para_mini, columns=features_names_para_mini)\n",
        "# Concatenate the dataframes\n",
        "df_proc_para_mini_class_onehot = pd.concat([df_proc_onehot, df_emb_para_mini_proc], axis=1)\n",
        "\n",
        "# Save the para_base dataframe\n",
        "df_emb_para_base_proc = pd.DataFrame(proc_embeddings_para_base, columns=features_names_para_base)\n",
        "# Concatenate the dataframes\n",
        "df_proc_para_base_class_onehot = pd.concat([df_proc_onehot, df_emb_para_base_proc], axis=1)"
      ],
      "metadata": {
        "id": "3suVVHwcnnq6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us save the dataframes to csv files so we can easily load them in the future."
      ],
      "metadata": {
        "id": "8xgTTW8hvNmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# Save the datasets to csv files\n",
        "df_orig_distiluse_class_onehot.to_csv('df-orig-distil-class-onehot.csv', index=False)\n",
        "df_orig_para_mini_class_onehot.to_csv('df-orig-para-mini-class-onehot.csv', index=False)\n",
        "df_orig_para_base_class_onehot.to_csv('df-orig-para-base-class-onehot.csv', index=False)\n",
        "\n",
        "df_proc_distiluse_class_onehot.to_csv('df-proc-distil-class-onehot.csv', index=False)\n",
        "df_proc_para_mini_class_onehot.to_csv('df-proc-para-mini-class-onehot.csv', index=False)\n",
        "df_proc_para_base_class_onehot.to_csv('df-proc-para-base-class-onehot.csv', index=False)"
      ],
      "metadata": {
        "id": "t6YOsF75u_ze"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us do label encoding on the target variable. "
      ],
      "metadata": {
        "id": "pAtRpYUcHobZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Label encoding of the target variable\n",
        "df_orig_le = df_orig.copy()\n",
        "df_proc_le = df_proc.copy()\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "df_orig_le['ClassLabel'] = le.fit_transform(df_orig['Class1'])\n",
        "df_proc_le['ClassLabel'] = le.fit_transform(df_proc['Class1'])\n",
        "\n",
        "print(df_orig_le)\n",
        "print(df_proc_le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3YafeyVHuOt",
        "outputId": "eed32414-1840-4f05-fb2b-89b0e485c961"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             ArticleName ArticleGroupName      Class1  \\\n",
            "0                 Carlsberg Export 50 cl               Öl        Beer   \n",
            "1                             Drink 4 cl            Sprit     Spirits   \n",
            "2                          Erdinger Hefe               Öl        Beer   \n",
            "3                          Guinness 50cl               Öl        Beer   \n",
            "4                      Staropramen 50 cl               Öl        Beer   \n",
            "..                                   ...              ...         ...   \n",
            "563                   EXTRA TAVO VEG 1ST              Mat  VariedFood   \n",
            "564                Carlsberg Export 40cl    Fatöl Starköl        Beer   \n",
            "565  Les Cardounettes Blanc EKO (FRA) GL              Vin        Wine   \n",
            "566               Crispy Halloumi Burger              Mat      Burger   \n",
            "567                      Öppen Aktivitet      Aktiviteter       Other   \n",
            "\n",
            "     ClassLabel  \n",
            "0             0  \n",
            "1            10  \n",
            "2             0  \n",
            "3             0  \n",
            "4             0  \n",
            "..          ...  \n",
            "563          11  \n",
            "564           0  \n",
            "565          12  \n",
            "566           1  \n",
            "567           7  \n",
            "\n",
            "[568 rows x 4 columns]\n",
            "                             ArticleName ArticleGroupName      Class1  \\\n",
            "0                       Carlsberg Export               Öl        Beer   \n",
            "1                                  Drink            Sprit     Spirits   \n",
            "2                          Erdinger Hefe               Öl        Beer   \n",
            "3                               Guinness               Öl        Beer   \n",
            "4                            Staropramen               Öl        Beer   \n",
            "..                                   ...              ...         ...   \n",
            "459                     Carlsberg Export    Fatöl Starköl        Beer   \n",
            "460                       EXTRA TAVO VEG              Mat  VariedFood   \n",
            "461  Les Cardounettes Blanc EKO (FRA) GL              Vin        Wine   \n",
            "462               Crispy Halloumi Burger              Mat      Burger   \n",
            "463                      Öppen Aktivitet      Aktiviteter       Other   \n",
            "\n",
            "     ClassLabel  \n",
            "0             0  \n",
            "1            10  \n",
            "2             0  \n",
            "3             0  \n",
            "4             0  \n",
            "..          ...  \n",
            "459           0  \n",
            "460          11  \n",
            "461          12  \n",
            "462           1  \n",
            "463           7  \n",
            "\n",
            "[464 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the original dataset\n",
        "# Save the embeddings into the dataframe\n",
        "# Create names of features for distiluse\n",
        "features_names_distiluse = []\n",
        "for i in range(len(orig_embeddings_distiluse[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_distiluse.append(name)\n",
        "\n",
        "# Create names of features for para-mini\n",
        "features_names_para_mini = []\n",
        "for i in range(len(orig_embeddings_para_mini[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_mini.append(name)\n",
        "\n",
        "# Create names of features for para-base\n",
        "features_names_para_base = []\n",
        "for i in range(len(orig_embeddings_para_base[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_base.append(name)\n",
        "\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_orig_distiluse_class_le = pd.concat([df_orig_le, df_emb_distiluse_orig], axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_orig_para_mini_class_le = pd.concat([df_orig_le, df_emb_para_mini_orig], axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_orig_para_base_class_le = pd.concat([df_orig_le, df_emb_para_base_orig], axis=1)"
      ],
      "metadata": {
        "id": "5EjXvcQPSzLq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the processed dataset\n",
        "# Save the embeddings into the dataframe\n",
        "# Create names of features for distiluse\n",
        "features_names_distiluse = []\n",
        "for i in range(len(proc_embeddings_distiluse[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_distiluse.append(name)\n",
        "\n",
        "# Create names of features for para-mini\n",
        "features_names_para_mini = []\n",
        "for i in range(len(proc_embeddings_para_mini[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_mini.append(name)\n",
        "\n",
        "# Create names of features for para-base\n",
        "features_names_para_base = []\n",
        "for i in range(len(proc_embeddings_para_base[0])):\n",
        "  name = 'f' + str(i+1)\n",
        "  features_names_para_base.append(name)\n",
        "\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_proc_distiluse_class_le = pd.concat([df_proc_le, df_emb_distiluse_proc], axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_proc_para_mini_class_le = pd.concat([df_proc_le, df_emb_para_mini_proc], axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df_proc_para_base_class_le = pd.concat([df_proc_le, df_emb_para_base_proc], axis=1)"
      ],
      "metadata": {
        "id": "40ImiVHQtHSG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# Save the datasets to csv files\n",
        "df_orig_distiluse_class_le.to_csv('df-orig-distil-class-le.csv', index=False)\n",
        "df_orig_para_mini_class_le.to_csv('df-orig-para-mini-class-le.csv', index=False)\n",
        "df_orig_para_base_class_le.to_csv('df-orig-para-base-class-le.csv', index=False)\n",
        "\n",
        "df_proc_distiluse_class_le.to_csv('df-proc-distil-class-le.csv', index=False)\n",
        "df_proc_para_mini_class_le.to_csv('df-proc-para-mini-class-le.csv', index=False)\n",
        "df_proc_para_base_class_le.to_csv('df-proc-para-base-class-le.csv', index=False)"
      ],
      "metadata": {
        "id": "eiC5PEuwTIAE"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}